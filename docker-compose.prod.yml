services:
  dnd-bot:
    platform: linux/arm64
    build: .
    container_name: dnd-bot-prod
    restart: unless-stopped
    depends_on:
      - redis
      - ollama
    env_file:
      - .env
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434/v1
    volumes:
      # Persistenza dati (NON codice sorgente)
      - ./recordings:/app/recordings
      - ./data:/app/data
      - ./batch_processing:/app/batch_processing

  redis:
    image: redis:alpine
    container_name: redis-server-prod
    restart: always
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-server
    restart: always
    volumes:
      - ollama_data:/root/.ollama
    ports:
      # Esposto solo internamente tra i container, ma se vuoi testarlo da fuori scommenta:
      # - "11434:11434"
      - "11434"

  # Servizio "One-Shot" per scaricare i modelli all'avvio
  ollama-puller:
    image: ollama/ollama:latest
    container_name: ollama-model-puller
    restart: "no" # Esegue una volta e si ferma
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=ollama:11434
    entrypoint: /bin/sh
    # Script: Aspetta che Ollama risponda, poi scarica i modelli necessari
    command: -c "echo 'Waiting for Ollama server...'; until ollama list > /dev/null 2>&1; do sleep 2; done; echo 'Ollama is ready. Pulling models...'; ollama pull nomic-embed-text; ollama pull llama3.2; echo 'All models pulled successfully!'"

volumes:
  ollama_data:
  redis_data:
