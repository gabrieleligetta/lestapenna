services:
  # 1. IL NOSTRO BOT (Node + Python Whisper)
  dnd-bot:
    build: .
    container_name: dnd-bot-container
    restart: unless-stopped
    env_file:
      - .env
    # depends_on:
    #   - ollama # Aspetta che Ollama parta
    volumes:
      - ./src:/app/src
      - ./package.json:/app/package.json
      - ./tsconfig.json:/app/tsconfig.json
      - ./yarn.lock:/app/yarn.lock
      - ./transcribe.py:/app/transcribe.py
      - ./recordings:/app/recordings
      - ./batch_processing:/app/batch_processing
      - ./hf_cache:/root/.cache/huggingface
      - ./data:/app/data
    # command rimosso: usiamo il CMD del Dockerfile che lancia "yarn dev"
    deploy:
      resources:
        limits:
          cpus: '2.0'
          memory: 4096M

  # 2. IL CERVELLO (Ollama Containerizzato)
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: ollama-server
  #   restart: always
  #   ports:
  #     - "11434:11434" # Espone la porta (utile per testare dal Mac o per debug)
  #   volumes:
  #     - ollama_data:/root/.ollama # Salva i modelli scaricati qui

volumes:
  ollama_data: # Volume persistente gestito da Docker
