services:
  dnd-bot:
    # Aggiungi questa riga per forzare l'architettura ARM64
    platform: linux/arm64
    build: .
    container_name: dnd-bot-container
    restart: unless-stopped
    env_file:
      - .env
    environment:
      - NODE_ENV=development
    depends_on:
      - redis
    # Override del comando di default (che ora è node dist/index.js) per usare dev mode
    command: yarn dev
    ports:
      - "3999:3999"
    volumes:
      # Mappatura corretta su /app
      - ./src:/app/src
      - ./package.json:/app/package.json
      - ./tsconfig.json:/app/tsconfig.json
      - ./yarn.lock:/app/yarn.lock
      - ./recordings:/app/recordings
      - ./batch_processing:/app/batch_processing
      - ./data:/app/data

  redis:
    image: redis:alpine
    container_name: redis-server
    restart: always
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    ports:
      - "6379:6379"

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-container
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # RIMOSSO IL BLOCCO 'deploy' CON NVIDIA DRIVER
    environment:
      # CPU OPTIMIZATION:
      # Anche se hai 24GB di RAM, elaborare 64k token su CPU è lentissimo.
      # 8192 o 16384 è un compromesso migliore tra memoria e velocità.
      - OLLAMA_NUM_CTX=8192

      # Mantiene il modello in RAM per evitare il tempo di caricamento (es. 24h)
      - OLLAMA_KEEP_ALIVE=24h

      # Limitiamo i thread per non soffocare il sistema (lasciamo 1 core libero per Node.js/OS)
      - OLLAMA_NUM_PARALLEL=1

      # Permette connessioni dall'esterno del container
      - OLLAMA_HOST=0.0.0.0
    restart: unless-stopped

volumes:
  ollama_data:
  redis_data:
