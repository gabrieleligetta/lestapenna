services:
  dnd-bot:
    platform: linux/arm64
    build: .
    container_name: dnd-bot-prod
    restart: unless-stopped
    depends_on:
      - redis
      - ollama
    env_file:
      - .env
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434/v1
      - TZ=Europe/Rome

    deploy:
      resources:
        limits:
          # Rimosso limite CPU per permettere la gestione interna tramite 'nice' e '-t 3'
          memory: 22G

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

    volumes:
      - ./recordings:/app/recordings
      - ./data:/app/data
      - ./batch_processing:/app/batch_processing

  redis:
    image: redis:alpine
    container_name: redis-server-prod
    restart: always
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ollama:
    image: ollama/ollama:latest
    container_name: ollama-server
    restart: always
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  ollama-puller:
    image: ollama/ollama:latest
    container_name: ollama-model-puller
    restart: "no"
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=ollama:11434
    entrypoint: /bin/sh
    command: -c "echo 'Waiting for Ollama server...'; until ollama list > /dev/null 2>&1; do sleep 2; done; echo 'Ollama is ready. Pulling models...'; ollama pull nomic-embed-text; ollama pull llama3.2; echo 'All models pulled successfully!'"

volumes:
  ollama_data:
  redis_data:
